import sys
import logging
import argparse
import torch
import torch.nn as nn
from collections import OrderedDict

sys.path.append("/src")

logging.basicConfig(
    level=logging.INFO,
    filemode="w",
    filename="./logs/discriminator.log/",
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
from generator import Generator


class Discriminator(nn.Module):
    """
    A Discriminator class representing a neural network model for distinguishing real images from generated ones.

    This class inherits from nn.Module and constructs a neural network discriminator model suitable for a Generative
    Adversarial Network (GAN). The discriminator is designed to take flattened image inputs (such as those from the
    MNIST dataset) and output a single value indicating the likelihood that the image is real.

    Attributes:
        model (torch.nn.Sequential): A sequential container of layers forming the discriminator network. The architecture
                                     is defined based on the layers configuration provided in `layers_config`.

    Methods:
        forward(x): Defines the forward pass of the discriminator.

    Parameters:
        layers_config (list of tuples): Each tuple in the list contains configuration for a layer in the model,
                                        including the number of input features, output features, and the negative
                                        slope for the LeakyReLU activation function. The last layer uses a Sigmoid
                                        activation function instead of LeakyReLU.
    """

    def __init__(self):
        super(Discriminator, self).__init__()

        layers_config = [
            (28 * 28, 512, 0.2),
            (512, 256, 0.2),
            (256, 1),
        ]
        self.model = self.discriminator_block(layers_config)

    def discriminator_block(self, layers_config):
        """
        Builds the discriminator block based on the provided layers configuration.

        Args:
            layers_config (list of tuples): Configuration for each layer in the discriminator model.

        Returns:
            torch.nn.Sequential: A sequential container of layers forming the discriminator network.
        """
        layers = OrderedDict()
        for index, (input_features, output_features, negative_slope) in enumerate(
            layers_config[:-1]
        ):
            layers[f"{index}_layer"] = nn.Linear(
                in_features=input_features, out_features=output_features
            )
            layers[f"{index}_activation"] = nn.LeakyReLU(negative_slope=negative_slope)

        # Output layer with Sigmoid activation
        layers["output_layer"] = nn.Linear(
            in_features=layers_config[-1][0], out_features=layers_config[-1][1]
        )
        layers["output_activation"] = nn.Sigmoid()

        return nn.Sequential(layers)

    def forward(self, x):
        """
        Defines the forward pass of the discriminator.

        Args:
            x (torch.Tensor): The input tensor containing the image data.

        Returns:
            torch.Tensor: The output of the discriminator, representing the probability that the input image is real.
        """
        if x is not None:
            x = x.view(-1, 28 * 28)
            x = self.model(x)
        else:
            x = "ERROR"
        return x


if __name__ == "__main__":
    """
    This script is designed for configuring and testing the discriminator component of a Generative
    Adversarial Network (GAN) model. It uses command-line arguments to set up the discriminator's
    parameters and subsequently evaluates its ability to classify fake data generated by the GAN's generator.

    The script facilitates specifying the batch size for training and the dimensionality of the latent
    space. Additionally, it includes a flag to define the discriminator model. When the discriminator is
    defined, the script generates noise samples, uses a generator to create fake samples from these noise
    samples, and then feeds these fake samples into the discriminator. The output, i.e., the discriminator's
    predictions on these fake samples, is then logged along with their shape.

    Command Line Arguments:
    - --batch_size (int): Batch size for training. Defaults to 64.
    - --latent_space (int): Dimensionality of the latent space. Defaults to 10.
    - --discriminator (flag): Flag to define and use the discriminator model.

    The script expects predefined `Generator` and `Discriminator` classes and utilizes `torch.randn` to
    create noise samples. It also uses a logging module to log information and exceptions.

    Examples:
    python script.py --batch_size 64 --latent_space 10 --discriminator
    python script.py --discriminator

    Note:
    - The script presumes the availability of a configured logging module (`logging`) for logging
    information and exceptions.
    - The `Generator` and `Discriminator` classes must be defined and accessible within the script's scope.
    - The script is intended for execution in an environment where `argparse` and `torch` libraries are available.
    """
    parser = argparse.ArgumentParser(description="Discriminator a GAN model.")

    parser.add_argument(
        "--batch_size", type=int, default=64, help="Batch size for training.".title()
    )
    parser.add_argument(
        "--latent_space",
        type=int,
        default=10,
        help="Number of latent space to train for.".title(),
    )
    parser.add_argument(
        "--discriminator",
        action="store_true",
        help="Define the discriminator model".title(),
    )

    args = parser.parse_args()

    if args.discriminator:
        if args.latent_space and args.batch_size:
            logging.info("Discriminator is being defined".capitalize())

            noise_samples = torch.randn(args.batch_size, args.latent_space)
            logging.info(f"Noise samples: {noise_samples}")
            logging.info(
                "Generator model is called to generate the dataset".capitalize()
            )

            generator = Generator(args.latent_space)
            fake_samples = generator(noise_samples)

            discriminator = Discriminator()
            fake_predicted = discriminator(fake_samples)

            print("The shape of fake samples # {}".format(fake_predicted.shape))
            logging.info("The shape of fake samples # {}".format(fake_predicted.shape))
        else:
            logging.exception(
                "Latent space and batch size is not defined yet".capitalize()
            )
    else:
        logging.exception("Discriminator is not defined yet".capitalize())
