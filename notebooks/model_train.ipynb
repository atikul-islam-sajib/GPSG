{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "mnist_data = datasets.MNIST(\n",
    "    root=\"data/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "dataloader = DataLoader(mnist_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of this dataset: torch.Size([32, 1, 28, 28]) \n",
      "# of the dataset that I downloaded = 60000 \n"
     ]
    }
   ],
   "source": [
    "#Check the dataset\n",
    "total_train = 0\n",
    "for features, label in dataloader:\n",
    "    total_train = total_train + features.shape[0]\n",
    "\n",
    "print(\"The shape of this dataset: {} \".format(features.shape))\n",
    "print(\"# of the dataset that I downloaded = {} \".format(total_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 784])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.reshape(-1, 28*28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    A generative neural network model for generating images using the DCGAN architecture.\n",
    "\n",
    "    Args:\n",
    "        latent_space (int): The dimensionality of the latent space noise vector. Default is 100.\n",
    "\n",
    "    Attributes:\n",
    "        latent_space (int): The dimensionality of the latent space noise vector.\n",
    "        model (nn.Sequential): The generator model composed of several layers.\n",
    "\n",
    "    Example:\n",
    "        >>> generator = Generator(latent_space=100)\n",
    "        >>> noise = torch.randn(64, 100)\n",
    "        >>> generated_images = generator(noise)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, latent_space=100):\n",
    "        \"\"\"\n",
    "        Initialize the Generator.\n",
    "\n",
    "        Args:\n",
    "            latent_space (int, optional): The dimensionality of the latent space noise vector. Default is 100.\n",
    "        \"\"\"\n",
    "        self.latent_space = latent_space\n",
    "        super(Generator, self).__init__()\n",
    "        layers_config = [\n",
    "            (self.latent_space, 256, 0.02),\n",
    "            (256, 512, 0.02),\n",
    "            (512, 1024, 0.02),\n",
    "            (1024, 28 * 28),\n",
    "        ]\n",
    "        self.model = self.generate_layer(layers_config=layers_config)\n",
    "\n",
    "    def generate_layer(self, layers_config):\n",
    "        \"\"\"\n",
    "        Create the layers of the generator model based on the provided configuration.\n",
    "\n",
    "        Args:\n",
    "            layers_config (list): A list of tuples specifying the layer configurations.\n",
    "\n",
    "        Returns:\n",
    "            nn.Sequential: A sequential model containing the specified layers.\n",
    "\n",
    "        Example:\n",
    "            >>> layers_config = [(100, 256, 0.02), (256, 512, 0.02), (512, 1024, 0.02), (1024, 28*28)]\n",
    "            >>> generator = Generator()\n",
    "            >>> generator_model = generator.generate_layer(layers_config)\n",
    "        \"\"\"\n",
    "        layers = OrderedDict()\n",
    "        for index, (input_feature, out_feature, negative_slope) in enumerate(\n",
    "            layers_config[:-1]\n",
    "        ):\n",
    "            layers[f\"layer_{index}\"] = nn.Linear(\n",
    "                in_features=input_feature, out_features=out_feature\n",
    "            )\n",
    "            layers[f\"layer_{index}_activation\"] = nn.LeakyReLU(\n",
    "                negative_slope=negative_slope\n",
    "            )\n",
    "\n",
    "        layers[f\"output_layer\"] = nn.Linear(\n",
    "            in_features=layers_config[-1][0], out_features=layers_config[-1][1]\n",
    "        )\n",
    "        layers[f\"output_layer_activation\"] = nn.Tanh()\n",
    "\n",
    "        return nn.Sequential(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the generator model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input noise tensor sampled from the latent space.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Generated images.\n",
    "\n",
    "        Example:\n",
    "            >>> noise = torch.randn(64, 100)\n",
    "            >>> generated_images = generator(noise)\n",
    "        \"\"\"\n",
    "        if x is not None:\n",
    "            x = self.model(x)\n",
    "        else:\n",
    "            x = -1\n",
    "\n",
    "        return x.reshape(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Generator(\n",
      "  (model): Sequential(\n",
      "    (layer_0): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (layer_0_activation): LeakyReLU(negative_slope=0.02)\n",
      "    (layer_1): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (layer_1_activation): LeakyReLU(negative_slope=0.02)\n",
      "    (layer_2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (layer_2_activation): LeakyReLU(negative_slope=0.02)\n",
      "    (output_layer): Linear(in_features=1024, out_features=784, bias=True)\n",
      "    (output_layer_activation): Tanh()\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "generator = Generator()\n",
    "\n",
    "print(generator.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.layer_0.weight & # of parameters: 25600 \n",
      "Layer: model.layer_0.bias & # of parameters: 256 \n",
      "Layer: model.layer_1.weight & # of parameters: 131072 \n",
      "Layer: model.layer_1.bias & # of parameters: 512 \n",
      "Layer: model.layer_2.weight & # of parameters: 524288 \n",
      "Layer: model.layer_2.bias & # of parameters: 1024 \n",
      "Layer: model.output_layer.weight & # of parameters: 802816 \n",
      "Layer: model.output_layer.bias & # of parameters: 784 \n",
      "\n",
      "TOTAL NUMBER OF PARAMETERS OF GENERATOR IS 1486352 \n"
     ]
    }
   ],
   "source": [
    "# Total number of parameters of Generator\n",
    "\n",
    "total_parameters = 0\n",
    "for layer, params in generator.named_parameters():\n",
    "    total_parameters += params.numel()\n",
    "    print(\"Layer: {} & # of parameters: {} \".format(layer, params.numel()))\n",
    "\n",
    "\n",
    "print(\n",
    "    \"\\nTotal number of parameters of generator is {} \".format(total_parameters).upper()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    A Discriminator class representing a neural network model for distinguishing real images from generated ones.\n",
    "\n",
    "    This class inherits from nn.Module and constructs a neural network discriminator model suitable for a Generative\n",
    "    Adversarial Network (GAN). The discriminator is designed to take flattened image inputs (such as those from the\n",
    "    MNIST dataset) and output a single value indicating the likelihood that the image is real.\n",
    "\n",
    "    Attributes:\n",
    "        model (torch.nn.Sequential): A sequential container of layers forming the discriminator network. The architecture\n",
    "                                     is defined based on the layers configuration provided in `layers_config`.\n",
    "\n",
    "    Methods:\n",
    "        forward(x): Defines the forward pass of the discriminator.\n",
    "\n",
    "    Parameters:\n",
    "        layers_config (list of tuples): Each tuple in the list contains configuration for a layer in the model,\n",
    "                                        including the number of input features, output features, and the negative\n",
    "                                        slope for the LeakyReLU activation function. The last layer uses a Sigmoid\n",
    "                                        activation function instead of LeakyReLU.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        layers_config = [\n",
    "            (28 * 28, 512, 0.02),\n",
    "            (512, 256, 0.02),\n",
    "            (\n",
    "                256,\n",
    "                1,\n",
    "            ),  # No negative slope for the last layer as it uses a Sigmoid activation\n",
    "        ]\n",
    "        self.model = self.discriminator_block(layers_config)\n",
    "\n",
    "    def discriminator_block(self, layers_config):\n",
    "        \"\"\"\n",
    "        Builds the discriminator block based on the provided layers configuration.\n",
    "\n",
    "        Args:\n",
    "            layers_config (list of tuples): Configuration for each layer in the discriminator model.\n",
    "\n",
    "        Returns:\n",
    "            torch.nn.Sequential: A sequential container of layers forming the discriminator network.\n",
    "        \"\"\"\n",
    "        layers = OrderedDict()\n",
    "        for index, (input_features, output_features, negative_slope) in enumerate(\n",
    "            layers_config[:-1]\n",
    "        ):\n",
    "            layers[f\"{index}_layer\"] = nn.Linear(\n",
    "                in_features=input_features, out_features=output_features\n",
    "            )\n",
    "            layers[f\"{index}_activation\"] = nn.LeakyReLU(negative_slope=negative_slope)\n",
    "\n",
    "        # Output layer with Sigmoid activation\n",
    "        layers[\"output_layer\"] = nn.Linear(\n",
    "            in_features=layers_config[-1][0], out_features=layers_config[-1][1]\n",
    "        )\n",
    "        layers[\"output_activation\"] = nn.Sigmoid()\n",
    "\n",
    "        return nn.Sequential(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the discriminator.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor containing the image data.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output of the discriminator, representing the probability that the input image is real.\n",
    "        \"\"\"\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the input\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Discriminator(\n",
      "  (model): Sequential(\n",
      "    (0_layer): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (0_activation): LeakyReLU(negative_slope=0.02)\n",
      "    (1_layer): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1_activation): LeakyReLU(negative_slope=0.02)\n",
      "    (output_layer): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (output_activation): Sigmoid()\n",
      "  )\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator()\n",
    "\n",
    "print(discriminator.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.0_layer.weight & # of parameters: 401408 \n",
      "Layer: model.0_layer.bias & # of parameters: 512 \n",
      "Layer: model.1_layer.weight & # of parameters: 131072 \n",
      "Layer: model.1_layer.bias & # of parameters: 256 \n",
      "Layer: model.output_layer.weight & # of parameters: 256 \n",
      "Layer: model.output_layer.bias & # of parameters: 1 \n",
      "\n",
      "TOTAL NUMBER OF PARAMETERS OF DISCRIMINATOR IS 533505 \n"
     ]
    }
   ],
   "source": [
    "# Total number of parameters of Discriminator\n",
    "\n",
    "total_parameters = 0\n",
    "for layer, params in discriminator.named_parameters():\n",
    "    total_parameters+=params.numel()\n",
    "    print(\"Layer: {} & # of parameters: {} \".format(layer, params.numel()))\n",
    "    \n",
    "\n",
    "print(\"\\nTotal number of parameters of discriminator is {} \".format(total_parameters).upper()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPSG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
